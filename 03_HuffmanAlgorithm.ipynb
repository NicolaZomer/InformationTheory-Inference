{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huffman Algorithm\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In lossless coding information compression is achieved by mapping messages into binary strings of variable length. This mapping is called *symbol coding* and should satisfy 3 properties:\n",
    "1. Unique decodability\n",
    "2. Prefix codes (aka self-punctuating codes)\n",
    "3. Minimal length\n",
    "\n",
    "A necessary condition for unique decodability is given by the *Kraft inequality*:\n",
    "$$\n",
    "    \\sum_i 2^{-l_i} \\leq 1\n",
    "$$\n",
    "where $l_i$ is the length of the codeword $i$. A code that saturates the Kraft inequality is called *complete code*, and it is possible to prof that there is a one-to-one correspondence between complete prefix codes and complete binary trees. In other words, prefix codes built from complete binary graphs saturate the inequality.\n",
    "\n",
    "## Source coding theorem for symbol codes\n",
    "For a random variable $X \\in \\mathcal{A}_X$ there exists a symbol code $E$ satisfying:\n",
    "$$\n",
    "    H[X] \\leq L(E,X) \\leq H[X] +1 \n",
    "$$\n",
    "Moreover, for all symbol codes $E'$ satisfying Kraft inequality we have that $L(E', X) \\geq H[X]$.\n",
    "\n",
    "## Huffman Algorithm\n",
    "It is possible to realize an algorithm to find optimal codes, i.e. prefix codes with minimal length. Recall that minimal length is achived in terms of average length of the encoded message, so what we want to minimize is $ L[E,X] = \\sum _i p_i l_i$. The Huffman Algorithm allows to build optimal codes using a recursive procedure to construct an optimal binary tree, starting from the leaves. \n",
    "\n",
    "The algorithm's steps are the following:\n",
    "1. Create nodes for all elementary outcomes\n",
    "2. Identify a pair of nodes associated to events with lowest probability\n",
    "3. Create a parent node having these two outcomes as children\n",
    "4. Iterate the procedure, considering only nodes with no parents\n",
    "5. Stop when only 1 node without parents is left\n",
    "\n",
    "Notice that the selection in step (2) might not be unique, so there can be different optimal codes, and the solution given by the Huffman Algorithm is not unique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Huffman_Algorithm(probabilities, events=None, return_tree=False):\n",
    "    '''\n",
    "    INPUT:\n",
    "    - probabilities: numpy array of probabilities \n",
    "    - events: numpy array of events' names \n",
    "    - return_tree: if true, return the tree\n",
    "    \n",
    "    Each event is associated to the corresponding probability\n",
    "    \n",
    "    OUTPUT:\n",
    "    - codewords: list of binary strings associated to each event (aka, the symbol code)\n",
    "    - tree: the resulting complete binary tree. It is returned as a list of elements, where each element is a list of nodes corresponding to a level \n",
    "            in the tree, from top to bottom.\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    # check if input are numpy arrays\n",
    "    assert isinstance(probabilities, np.ndarray), 'probabilities must be a numpy array'\n",
    "    assert isinstance(events, np.ndarray) or events is None, 'events must be a numpy array'\n",
    "    \n",
    "    # vector of events like (x1, x2, x3, ...)\n",
    "    n_events = len(probabilities)\n",
    "    myevents = np.array(['x'+str(i+1) for i in range(n_events)])\n",
    "    \n",
    "    # initialization\n",
    "    codewords = ['']*n_events\n",
    "    \n",
    "    prob_noparent = probabilities\n",
    "    node_noparent = np.array(myevents)\n",
    "    \n",
    "    num_nodes_noparent = n_events    \n",
    "    \n",
    "    # algorithm \n",
    "    while num_nodes_noparent > 1:\n",
    "        # select a pair of nodes with lowest probability\n",
    "        mask = np.argsort(prob_noparent)[:2]\n",
    "        \n",
    "        selected_probs  = prob_noparent[mask]\n",
    "        selected_events = node_noparent[mask]\n",
    "        \n",
    "        # update codewords\n",
    "        index_0 = np.array(re.findall(r'\\d+', selected_events[0])).astype(int)-1\n",
    "        index_1 = np.array(re.findall(r'\\d+', selected_events[1])).astype(int)-1\n",
    "        \n",
    "        for i in index_0:\n",
    "            codewords[i] = '0' + codewords[i]\n",
    "    \n",
    "        for i in index_1:\n",
    "            codewords[i] = '1' + codewords[i] \n",
    "        \n",
    "        # update probabilities and events without parents\n",
    "        prob_noparent = np.append(np.delete(prob_noparent, mask), sum(selected_probs))\n",
    "        node_noparent = np.append(np.delete(node_noparent, mask), selected_events[0]+selected_events[1])\n",
    "   \n",
    "        num_nodes_noparent -= 1\n",
    "                \n",
    "    return codewords\n",
    "\n",
    "\n",
    "def avg_length(probabilities, encoding):\n",
    "    '''\n",
    "    INPUT:\n",
    "    - probabilities: numpy array of probabilities \n",
    "    - encoding: list of binary strings associated to each probability \n",
    "        \n",
    "    OUTPUT:\n",
    "    - LE: average length\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    LE = np.dot(probabilities, np.array([len(code) for code in encoding]))\n",
    "    return LE\n",
    "\n",
    "\n",
    "def kraft_inequality(encoding):\n",
    "    '''\n",
    "    INPUT: \n",
    "    - encoding: list of binary strings associated to each probability \n",
    "        \n",
    "    OUTPUT:\n",
    "    - True if Kraft inequality is satisfied, False otherwise\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    kraft_bound = sum(np.exp2([-len(code) for code in encoding]))\n",
    "    \n",
    "    if kraft_bound<=1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    return np.dot(p, -np.log2(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the algorithm\n",
    "## Test 0\n",
    "First I test it considering 4 events with associated probabilities: $P_X= \\{1/2, 1/4, 1/8, 1/8\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code found by the Huffman Algorithm:\n",
      "x1: 0\n",
      "x2: 10\n",
      "x3: 110\n",
      "x4: 111\n"
     ]
    }
   ],
   "source": [
    "px_0 = np.array([1/2, 1/4, 1/8, 1/8])\n",
    "\n",
    "encoding_0 = Huffman_Algorithm(px_0)\n",
    "\n",
    "print('Code found by the Huffman Algorithm:')\n",
    "for i in range(len(px_0)):\n",
    "    print('x%i: %s' %(i+1, encoding_0[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the average length and compare it with the Shannon entropy of $X$. Let's see also if the Kraft inequality is satisfied or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length: L[E,X]=1.75\n",
      "Shannon entropy:  H[X]=1.75\n",
      "\n",
      "Is Kraft inequality satisfied? True\n"
     ]
    }
   ],
   "source": [
    "print('Average length: L[E,X]=%.2f' %(avg_length(px_0, encoding_0)))\n",
    "print('Shannon entropy:  H[X]=%.2f' %(entropy(px_0)))\n",
    "\n",
    "print('\\nIs Kraft inequality satisfied?', kraft_inequality(encoding_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1 \n",
    "I repeat the same test using the data of homework 02. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code found by the Huffman Algorithm:\n",
      "x1: 00\n",
      "x2: 01\n",
      "x3: 10\n",
      "x4: 111\n",
      "x5: 11000\n",
      "x6: 11001\n",
      "x7: 11010\n",
      "x8: 11011\n"
     ]
    }
   ],
   "source": [
    "px_1 = np.array([1/4, 1/4, 1/4, 3/16, 1/64, 1/64, 1/64, 1/64])\n",
    "\n",
    "encoding_1 = Huffman_Algorithm(px_1)\n",
    "\n",
    "print('Code found by the Huffman Algorithm:')\n",
    "for i in range(len(px_1)):\n",
    "    print('x%i: %s' %(i+1, encoding_1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length: L[E,X]=2.38\n",
      "Shannon entropy:  H[X]=2.33\n",
      "\n",
      "Is Kraft inequality satisfied? True\n"
     ]
    }
   ],
   "source": [
    "print('Average length: L[E,X]=%.2f' %(avg_length(px_1, encoding_1)))\n",
    "print('Shannon entropy:  H[X]=%.2f' %(entropy(px_1)))\n",
    "\n",
    "print('\\nIs Kraft inequality satisfied?', kraft_inequality(encoding_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2\n",
    "Finally, I want to apply it to the text that was given to us in homework 1. In this case I associate a code to each word in the text, and the corresponding probability is given by its relative occurrence. In the preprocessing I will only convert the test to lowercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import digits, punctuation\n",
    "\n",
    "# import file\n",
    "file = open('./text.txt')\n",
    "mytext = file.read()\n",
    "\n",
    "# preprocessing\n",
    "mytext = mytext.replace('ACT I', 'ACT 1').replace('ACT II', 'ACT 2').replace('ACT III', 'ACT 3')\n",
    "mytext = mytext.replace('SCENE I', 'SCENE 1').replace('SCENE II', 'SCENE 2').replace('SCENE III', 'SCENE 3')\n",
    "\n",
    "mytext = mytext.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the text (+ punctuation): 3085\n"
     ]
    }
   ],
   "source": [
    "mytext_list = re.findall(r\"[\\w]+|[^\\s\\w]\", mytext)\n",
    "\n",
    "# occurrences of unique words in the list\n",
    "values, counts = np.unique(mytext_list, return_counts=True)\n",
    "print('Number of unique words in the text (+ punctuation):', len(values))\n",
    "\n",
    "# probability distribution\n",
    "prob_text = counts/len(mytext_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length: L[E,X]=8.69\n",
      "Shannon entropy:  H[X]=8.66\n",
      "\n",
      "Is Kraft inequality satisfied? True\n"
     ]
    }
   ],
   "source": [
    "# Huffman Algorithm\n",
    "encoding_text = Huffman_Algorithm(prob_text)\n",
    "\n",
    "print('Average length: L[E,X]=%.2f' %(avg_length(prob_text, encoding_text)))\n",
    "print('Shannon entropy:  H[X]=%.2f' %(entropy(prob_text)))\n",
    "\n",
    "print('\\nIs Kraft inequality satisfied?', kraft_inequality(encoding_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dabd4eacb9e3ddd54eefcebcf933935be170cfdef29c95630fe9376e024beb9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
