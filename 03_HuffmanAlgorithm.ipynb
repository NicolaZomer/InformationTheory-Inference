{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huffman Algorithm\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In lossless coding information compression is achieved by mapping messages into binary strings of variable length. This mapping is called *symbol coding* and should satisfy 3 properties:\n",
    "1. Unique decodability\n",
    "2. Prefix codes (aka self-punctuating codes)\n",
    "3. Minimal length\n",
    "\n",
    "A necessary condition for unique decodability is given by the *Kraft inequality*:\n",
    "$$\n",
    "    \\sum_i 2^{-l_i} \\leq 1\n",
    "$$\n",
    "where $l_i$ is the length of the codeword $i$. A code that saturates the Kraft inequality is called *complete code*, and it is possible to prof that there is a one-to-one correspondence between complete prefix codes and complete binary trees. In other words, prefix codes built from complete binary graphs saturate the inequality.\n",
    "\n",
    "## Source coding theorem for symbol codes\n",
    "For a random variable $X \\in \\mathcal{A}_X$ there exists a symbol code $E$ satisfying:\n",
    "$$\n",
    "    H[X] \\leq L(E,X) \\leq H[X] +1 \n",
    "$$\n",
    "Moreover, for all symbol codes $E'$ satisfying Kraft inequality we have that $L(E', X) \\geq H[X]$.\n",
    "\n",
    "## Huffman Algorithm\n",
    "It is possible to realize an algorithm to find optimal codes, i.e. prefix codes with minimal length. Recall that minimal length is achived in terms of average length of the encoded message, so what we want to minimize is $ L[E,X] = \\sum _i p_i l_i$. The Huffman Algorithm allows to build optimal codes using a recursive procedure to construct an optimal binary tree, starting from the leaves. \n",
    "\n",
    "The algorithm's steps are the following:\n",
    "1. Create nodes for all elementary outcomes\n",
    "2. Identify a pair of nodes associated to events with lowest probability\n",
    "3. Create a parent node having these two outcomes as children\n",
    "4. Iterate the procedure, considering only nodes with no parents\n",
    "5. Stop when only 1 node without parents is left\n",
    "\n",
    "Notice that the selection in step (2) might not be unique, so there can be different optimal codes, and the solution given by the Huffman Algorithm is not unique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import graphviz\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Huffman_Algorithm(probabilities, return_tree=False):\n",
    "    '''\n",
    "    INPUT:\n",
    "    - probabilities: numpy array of probabilities \n",
    "    - return_tree: if true, return the tree\n",
    "        \n",
    "    OUTPUT:\n",
    "    - codewords: list of binary strings associated to each event (aka, the symbol code)\n",
    "    - tree_construction: the step by step construction of the binary tree. It is return as a list where each element contains the parent nodes at step i.\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    # check if input are numpy arrays\n",
    "    assert isinstance(probabilities, np.ndarray), 'probabilities must be a numpy array'\n",
    "    \n",
    "    # vector of events like (x1, x2, x3, ...)\n",
    "    n_events = len(probabilities)\n",
    "    myevents = np.array(['x'+str(i+1) for i in range(n_events)])\n",
    "        \n",
    "    if return_tree is True:\n",
    "        tree_construction = [myevents]\n",
    "    \n",
    "    # initialization\n",
    "    codewords = ['']*n_events\n",
    "    \n",
    "    prob_noparent = probabilities\n",
    "    node_noparent = np.array(myevents)\n",
    "    \n",
    "    num_nodes_noparent = n_events    \n",
    "    \n",
    "    # algorithm \n",
    "    while num_nodes_noparent > 1:\n",
    "        # select a pair of nodes with lowest probability\n",
    "        mask = np.sort(np.argsort(prob_noparent)[:2])\n",
    "        \n",
    "        selected_probs  = prob_noparent[mask]\n",
    "        selected_events = node_noparent[mask]\n",
    "        \n",
    "        # update codewords\n",
    "        index_0 = np.array(re.findall(r'\\d+', selected_events[0])).astype(int)-1\n",
    "        index_1 = np.array(re.findall(r'\\d+', selected_events[1])).astype(int)-1\n",
    "        \n",
    "        for i in index_0:\n",
    "            codewords[i] = '0' + codewords[i]\n",
    "    \n",
    "        for i in index_1:\n",
    "            codewords[i] = '1' + codewords[i] \n",
    "        \n",
    "        # update probabilities and events without parents\n",
    "        prob_noparent = np.append(np.delete(prob_noparent, mask), sum(selected_probs))\n",
    "        node_noparent = np.append(np.delete(node_noparent, mask), selected_events[0]+selected_events[1])\n",
    "        \n",
    "        # update tree if required\n",
    "        if return_tree:\n",
    "            selection = tree_construction[-1][mask]\n",
    "            tree_construction.append(np.append(np.delete(tree_construction[-1], mask), selection[0]+selection[1]))\n",
    "   \n",
    "        num_nodes_noparent -= 1\n",
    "        \n",
    "    if return_tree is True:\n",
    "        return codewords, [x.tolist() for x in tree_construction]\n",
    "\n",
    "    else:            \n",
    "        return codewords\n",
    "\n",
    "\n",
    "def avg_length(probabilities, encoding):\n",
    "    '''\n",
    "    INPUT:\n",
    "    - probabilities: numpy array of probabilities \n",
    "    - encoding: list of binary strings associated to each probability \n",
    "        \n",
    "    OUTPUT:\n",
    "    - LE: average length\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    LE = np.dot(probabilities, np.array([len(code) for code in encoding]))\n",
    "    return LE\n",
    "\n",
    "\n",
    "def kraft_inequality(encoding):\n",
    "    '''\n",
    "    INPUT: \n",
    "    - encoding: list of binary strings associated to each probability \n",
    "        \n",
    "    OUTPUT:\n",
    "    - True if Kraft inequality is satisfied, False otherwise\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    kraft_bound = sum(np.exp2([-len(code) for code in encoding]))\n",
    "    \n",
    "    if kraft_bound<=1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    return np.dot(p, -np.log2(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tree(HC_steps):\n",
    "    '''\n",
    "    INPUT: \n",
    "    - HC_steps: steps of the Huffman Algorithm \n",
    "        \n",
    "    OUTPUT:\n",
    "    - f: resulting binary tree \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # inizialize the tree\n",
    "    f = graphviz.Digraph('mytree', format='png')\n",
    "    \n",
    "    for x in HC_steps[0]:\n",
    "        f.node('L0_'+x, label=x)\n",
    "    \n",
    "    for i in range(1, len(HC_steps)):\n",
    "        # find new root and corresponding leaves\n",
    "        [root] = [item for item in HC_steps[i]   if item not in HC_steps[i-1]] #1\n",
    "        leaves = [item for item in HC_steps[i-1] if item not in HC_steps[i]]   #2\n",
    "        \n",
    "        # compute levels        \n",
    "        lev_r = len(re.findall(r'\\d+', root))-1\n",
    "        lev_l0 = len(re.findall(r'\\d+', leaves[0]))-1\n",
    "        lev_l1 = len(re.findall(r'\\d+', leaves[1]))-1\n",
    "        \n",
    "        # find nodes names\n",
    "        root_node = 'L'+str(lev_r)+'_'+root\n",
    "        leaf_node_0 = 'L'+str(lev_l0)+'_'+leaves[0]\n",
    "        leaf_node_1 = 'L'+str(lev_l1)+'_'+leaves[1]\n",
    "        \n",
    "        # create new node\n",
    "        f.node(root_node, label=root)\n",
    "        \n",
    "        # create edges\n",
    "        f.edge(root_node, leaf_node_0, label='0')\n",
    "        f.edge(root_node, leaf_node_1, label='1')\n",
    "        \n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the algorithm\n",
    "## Test 0\n",
    "First I test it considering 4 events with associated probabilities: $P_X= \\{1/2, 1/4, 1/8, 1/8\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code found by the Huffman Algorithm:\n",
      "x1: 0\n",
      "x2: 10\n",
      "x3: 110\n",
      "x4: 111\n"
     ]
    }
   ],
   "source": [
    "px_0 = np.array([1/2, 1/4, 1/8, 1/8])\n",
    "\n",
    "encoding_0, steps_0= Huffman_Algorithm(px_0, return_tree=True)\n",
    "\n",
    "print('Code found by the Huffman Algorithm:')\n",
    "for i in range(len(px_0)):\n",
    "    print('x%i: %s' %(i+1, encoding_0[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the average length and compare it with the Shannon entropy of $X$. Let's see also if the Kraft inequality is satisfied or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length: L[E,X]=1.75\n",
      "Shannon entropy:  H[X]=1.75\n",
      "\n",
      "Is Kraft inequality satisfied? True\n"
     ]
    }
   ],
   "source": [
    "print('Average length: L[E,X]=%.2f' %(avg_length(px_0, encoding_0)))\n",
    "print('Shannon entropy:  H[X]=%.2f' %(entropy(px_0)))\n",
    "\n",
    "print('\\nIs Kraft inequality satisfied?', kraft_inequality(encoding_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to plot the resulting complete binary tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.50.0 (0)\n -->\n<!-- Title: mytree Pages: 1 -->\n<svg width=\"232pt\" height=\"305pt\"\n viewBox=\"0.00 0.00 232.15 305.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 301)\">\n<title>mytree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-301 228.15,-301 228.15,4 -4,4\"/>\n<!-- L0_x1 -->\n<g id=\"node1\" class=\"node\">\n<title>L0_x1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"31.15\" cy=\"-192\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"31.15\" y=\"-188.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1</text>\n</g>\n<!-- L0_x2 -->\n<g id=\"node2\" class=\"node\">\n<title>L0_x2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"87.15\" cy=\"-105\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"87.15\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2</text>\n</g>\n<!-- L0_x3 -->\n<g id=\"node3\" class=\"node\">\n<title>L0_x3</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"125.15\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"125.15\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3</text>\n</g>\n<!-- L0_x4 -->\n<g id=\"node4\" class=\"node\">\n<title>L0_x4</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"197.15\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"197.15\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x4</text>\n</g>\n<!-- L1_x3x4 -->\n<g id=\"node5\" class=\"node\">\n<title>L1_x3x4</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"161.15\" cy=\"-105\" rx=\"28.7\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"161.15\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3x4</text>\n</g>\n<!-- L1_x3x4&#45;&gt;L0_x3 -->\n<g id=\"edge1\" class=\"edge\">\n<title>L1_x3x4&#45;&gt;L0_x3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154.03,-87.21C148.92,-75.14 141.93,-58.64 136.11,-44.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"139.24,-43.31 132.12,-35.47 132.8,-46.04 139.24,-43.31\"/>\n<text text-anchor=\"middle\" x=\"149.65\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- L1_x3x4&#45;&gt;L0_x4 -->\n<g id=\"edge2\" class=\"edge\">\n<title>L1_x3x4&#45;&gt;L0_x4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M168.26,-87.21C173.37,-75.14 180.36,-58.64 186.18,-44.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"189.49,-46.04 190.17,-35.47 183.05,-43.31 189.49,-46.04\"/>\n<text text-anchor=\"middle\" x=\"184.65\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- L2_x2x3x4 -->\n<g id=\"node6\" class=\"node\">\n<title>L2_x2x3x4</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"113.15\" cy=\"-192\" rx=\"37.09\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"113.15\" y=\"-188.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2x3x4</text>\n</g>\n<!-- L2_x2x3x4&#45;&gt;L0_x2 -->\n<g id=\"edge3\" class=\"edge\">\n<title>L2_x2x3x4&#45;&gt;L0_x2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M107.88,-173.8C104.27,-161.97 99.39,-146.03 95.28,-132.58\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"98.58,-131.42 92.31,-122.89 91.89,-133.47 98.58,-131.42\"/>\n<text text-anchor=\"middle\" x=\"105.65\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- L2_x2x3x4&#45;&gt;L1_x3x4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>L2_x2x3x4&#45;&gt;L1_x3x4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M122.63,-174.21C129.56,-161.94 139.06,-145.1 146.9,-131.22\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"150.14,-132.61 152.01,-122.18 144.04,-129.17 150.14,-132.61\"/>\n<text text-anchor=\"middle\" x=\"143.65\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- L3_x1x2x3x4 -->\n<g id=\"node7\" class=\"node\">\n<title>L3_x1x2x3x4</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"46.15\" cy=\"-279\" rx=\"46.29\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"46.15\" y=\"-275.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1x2x3x4</text>\n</g>\n<!-- L3_x1x2x3x4&#45;&gt;L0_x1 -->\n<g id=\"edge5\" class=\"edge\">\n<title>L3_x1x2x3x4&#45;&gt;L0_x1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M43.11,-260.8C41.06,-249.16 38.3,-233.55 35.95,-220.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"39.36,-219.41 34.18,-210.18 32.47,-220.63 39.36,-219.41\"/>\n<text text-anchor=\"middle\" x=\"43.65\" y=\"-231.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- L3_x1x2x3x4&#45;&gt;L2_x2x3x4 -->\n<g id=\"edge6\" class=\"edge\">\n<title>L3_x1x2x3x4&#45;&gt;L2_x2x3x4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M59.06,-261.61C69.05,-248.95 83.01,-231.24 94.24,-216.98\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"97.05,-219.07 100.49,-209.05 91.56,-214.74 97.05,-219.07\"/>\n<text text-anchor=\"middle\" x=\"87.65\" y=\"-231.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x21d4f031f40>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_tree(steps_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1 \n",
    "I repeat the same test using the data of homework 02. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code found by the Huffman Algorithm:\n",
      "x1: 00\n",
      "x2: 01\n",
      "x3: 10\n",
      "x4: 110\n",
      "x5: 11100\n",
      "x6: 11101\n",
      "x7: 11110\n",
      "x8: 11111\n"
     ]
    }
   ],
   "source": [
    "px_1 = np.array([1/4, 1/4, 1/4, 3/16, 1/64, 1/64, 1/64, 1/64])\n",
    "\n",
    "encoding_1, steps_1 = Huffman_Algorithm(px_1, return_tree=True)\n",
    "\n",
    "print('Code found by the Huffman Algorithm:')\n",
    "for i in range(len(px_1)):\n",
    "    print('x%i: %s' %(i+1, encoding_1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length: L[E,X]=2.375\n",
      "Shannon entropy:  H[X]=2.328\n",
      "\n",
      "Is Kraft inequality satisfied? True\n"
     ]
    }
   ],
   "source": [
    "print('Average length: L[E,X]=%.3f' %(avg_length(px_1, encoding_1)))\n",
    "print('Shannon entropy:  H[X]=%.3f' %(entropy(px_1)))\n",
    "\n",
    "print('\\nIs Kraft inequality satisfied?', kraft_inequality(encoding_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.50.0 (0)\n -->\n<!-- Title: mytree Pages: 1 -->\n<svg width=\"475pt\" height=\"479pt\"\n viewBox=\"0.00 0.00 475.00 479.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 475)\">\n<title>mytree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-475 471,-475 471,4 -4,4\"/>\n<!-- L0_x1 -->\n<g id=\"node1\" class=\"node\">\n<title>L0_x1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-279\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-275.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1</text>\n</g>\n<!-- L0_x2 -->\n<g id=\"node2\" class=\"node\">\n<title>L0_x2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-279\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"99\" y=\"-275.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2</text>\n</g>\n<!-- L0_x3 -->\n<g id=\"node3\" class=\"node\">\n<title>L0_x3</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"175\" cy=\"-279\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"175\" y=\"-275.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3</text>\n</g>\n<!-- L0_x4 -->\n<g id=\"node4\" class=\"node\">\n<title>L0_x4</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"245\" cy=\"-192\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"245\" y=\"-188.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x4</text>\n</g>\n<!-- L0_x5 -->\n<g id=\"node5\" class=\"node\">\n<title>L0_x5</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"223\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"223\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x5</text>\n</g>\n<!-- L0_x6 -->\n<g id=\"node6\" class=\"node\">\n<title>L0_x6</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"295\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"295\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x6</text>\n</g>\n<!-- L0_x7 -->\n<g id=\"node7\" class=\"node\">\n<title>L0_x7</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"368\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"368\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x7</text>\n</g>\n<!-- L0_x8 -->\n<g id=\"node8\" class=\"node\">\n<title>L0_x8</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"440\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"440\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x8</text>\n</g>\n<!-- L1_x5x6 -->\n<g id=\"node9\" class=\"node\">\n<title>L1_x5x6</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"294\" cy=\"-105\" rx=\"28.7\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"294\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x5x6</text>\n</g>\n<!-- L1_x5x6&#45;&gt;L0_x5 -->\n<g id=\"edge1\" class=\"edge\">\n<title>L1_x5x6&#45;&gt;L0_x5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M281.31,-88.8C270.4,-75.75 254.52,-56.74 242.08,-41.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"244.68,-39.5 235.58,-34.06 239.31,-43.98 244.68,-39.5\"/>\n<text text-anchor=\"middle\" x=\"266.5\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- L1_x5x6&#45;&gt;L0_x6 -->\n<g id=\"edge2\" class=\"edge\">\n<title>L1_x5x6&#45;&gt;L0_x6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M294.2,-86.8C294.34,-75.16 294.52,-59.55 294.68,-46.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"298.18,-46.22 294.8,-36.18 291.18,-46.13 298.18,-46.22\"/>\n<text text-anchor=\"middle\" x=\"298.5\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- L1_x7x8 -->\n<g id=\"node10\" class=\"node\">\n<title>L1_x7x8</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"369\" cy=\"-105\" rx=\"28.7\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"369\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x7x8</text>\n</g>\n<!-- L1_x7x8&#45;&gt;L0_x7 -->\n<g id=\"edge3\" class=\"edge\">\n<title>L1_x7x8&#45;&gt;L0_x7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M368.8,-86.8C368.66,-75.16 368.48,-59.55 368.32,-46.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"371.82,-46.13 368.2,-36.18 364.82,-46.22 371.82,-46.13\"/>\n<text text-anchor=\"middle\" x=\"372.5\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- L1_x7x8&#45;&gt;L0_x8 -->\n<g id=\"edge4\" class=\"edge\">\n<title>L1_x7x8&#45;&gt;L0_x8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M381.69,-88.8C392.6,-75.75 408.48,-56.74 420.92,-41.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"423.69,-43.98 427.42,-34.06 418.32,-39.5 423.69,-43.98\"/>\n<text text-anchor=\"middle\" x=\"412.5\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- L3_x5x6x7x8 -->\n<g id=\"node11\" class=\"node\">\n<title>L3_x5x6x7x8</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"336\" cy=\"-192\" rx=\"46.29\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"336\" y=\"-188.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x5x6x7x8</text>\n</g>\n<!-- L3_x5x6x7x8&#45;&gt;L1_x5x6 -->\n<g id=\"edge5\" class=\"edge\">\n<title>L3_x5x6x7x8&#45;&gt;L1_x5x6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M327.7,-174.21C321.68,-162.02 313.43,-145.32 306.6,-131.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"309.71,-129.88 302.14,-122.47 303.43,-132.98 309.71,-129.88\"/>\n<text text-anchor=\"middle\" x=\"321.5\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- L3_x5x6x7x8&#45;&gt;L1_x7x8 -->\n<g id=\"edge6\" class=\"edge\">\n<title>L3_x5x6x7x8&#45;&gt;L1_x7x8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M342.68,-173.8C347.3,-161.89 353.54,-145.82 358.78,-132.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"362.2,-133.19 362.56,-122.6 355.67,-130.65 362.2,-133.19\"/>\n<text text-anchor=\"middle\" x=\"358.5\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- L4_x4x5x6x7x8 -->\n<g id=\"node12\" class=\"node\">\n<title>L4_x4x5x6x7x8</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"275\" cy=\"-279\" rx=\"54.69\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"275\" y=\"-275.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x4x5x6x7x8</text>\n</g>\n<!-- L4_x4x5x6x7x8&#45;&gt;L0_x4 -->\n<g id=\"edge7\" class=\"edge\">\n<title>L4_x4x5x6x7x8&#45;&gt;L0_x4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M268.93,-260.8C264.73,-248.89 259.05,-232.82 254.29,-219.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"257.49,-217.86 250.86,-209.6 250.89,-220.19 257.49,-217.86\"/>\n<text text-anchor=\"middle\" x=\"265.5\" y=\"-231.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- L4_x4x5x6x7x8&#45;&gt;L3_x5x6x7x8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>L4_x4x5x6x7x8&#45;&gt;L3_x5x6x7x8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M287.05,-261.21C295.97,-248.79 308.25,-231.67 318.28,-217.7\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"321.19,-219.63 324.18,-209.47 315.51,-215.55 321.19,-219.63\"/>\n<text text-anchor=\"middle\" x=\"313.5\" y=\"-231.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- L1_x1x2 -->\n<g id=\"node13\" class=\"node\">\n<title>L1_x1x2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"81\" cy=\"-366\" rx=\"28.7\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"81\" y=\"-362.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1x2</text>\n</g>\n<!-- L1_x1x2&#45;&gt;L0_x1 -->\n<g id=\"edge9\" class=\"edge\">\n<title>L1_x1x2&#45;&gt;L0_x1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M70.84,-349.01C62.92,-336.55 51.78,-319.01 42.72,-304.74\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"45.43,-302.48 37.11,-295.92 39.52,-306.23 45.43,-302.48\"/>\n<text text-anchor=\"middle\" x=\"61.5\" y=\"-318.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- L1_x1x2&#45;&gt;L0_x2 -->\n<g id=\"edge10\" class=\"edge\">\n<title>L1_x1x2&#45;&gt;L0_x2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M84.64,-347.8C87.12,-336.09 90.46,-320.34 93.29,-306.97\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"96.78,-307.39 95.42,-296.89 89.93,-305.94 96.78,-307.39\"/>\n<text text-anchor=\"middle\" x=\"95.5\" y=\"-318.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- L5_x3x4x5x6x7x8 -->\n<g id=\"node14\" class=\"node\">\n<title>L5_x3x4x5x6x7x8</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"191\" cy=\"-366\" rx=\"63.89\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"191\" y=\"-362.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3x4x5x6x7x8</text>\n</g>\n<!-- L5_x3x4x5x6x7x8&#45;&gt;L0_x3 -->\n<g id=\"edge11\" class=\"edge\">\n<title>L5_x3x4x5x6x7x8&#45;&gt;L0_x3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M183.48,-347.85C181.34,-342.26 179.26,-335.96 178,-330 176.48,-322.8 175.64,-314.89 175.19,-307.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"178.68,-307.15 174.79,-297.29 171.68,-307.42 178.68,-307.15\"/>\n<text text-anchor=\"middle\" x=\"181.5\" y=\"-318.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- L5_x3x4x5x6x7x8&#45;&gt;L4_x4x5x6x7x8 -->\n<g id=\"edge12\" class=\"edge\">\n<title>L5_x3x4x5x6x7x8&#45;&gt;L4_x4x5x6x7x8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M207.6,-348.21C220.1,-335.55 237.42,-318.03 251.37,-303.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"254.18,-306.04 258.72,-296.47 249.21,-301.12 254.18,-306.04\"/>\n<text text-anchor=\"middle\" x=\"242.5\" y=\"-318.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- L7_x1x2x3x4x5x6x7x8 -->\n<g id=\"node15\" class=\"node\">\n<title>L7_x1x2x3x4x5x6x7x8</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"136\" cy=\"-453\" rx=\"81.49\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"136\" y=\"-449.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1x2x3x4x5x6x7x8</text>\n</g>\n<!-- L7_x1x2x3x4x5x6x7x8&#45;&gt;L1_x1x2 -->\n<g id=\"edge13\" class=\"edge\">\n<title>L7_x1x2x3x4x5x6x7x8&#45;&gt;L1_x1x2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M124.87,-434.8C116.84,-422.38 105.87,-405.44 96.91,-391.6\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"99.74,-389.52 91.37,-383.03 93.86,-393.32 99.74,-389.52\"/>\n<text text-anchor=\"middle\" x=\"115.5\" y=\"-405.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- L7_x1x2x3x4x5x6x7x8&#45;&gt;L5_x3x4x5x6x7x8 -->\n<g id=\"edge14\" class=\"edge\">\n<title>L7_x1x2x3x4x5x6x7x8&#45;&gt;L5_x3x4x5x6x7x8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M147.13,-434.8C155.01,-422.62 165.71,-406.09 174.57,-392.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"177.58,-394.18 180.07,-383.89 171.7,-390.38 177.58,-394.18\"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-405.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x21d4f031400>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_tree(steps_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2\n",
    "Finally, I want to apply it to the text that was given to us in homework 1. In this case I associate a code to each word in the text, and the corresponding probability is given by its relative occurrence. In the preprocessing I will only convert the test to lowercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import digits, punctuation\n",
    "\n",
    "# import file\n",
    "file = open('./text.txt')\n",
    "mytext = file.read()\n",
    "\n",
    "# preprocessing\n",
    "mytext = mytext.replace('ACT V', 'ACT 5').replace('ACT IV', 'ACT 4').replace('ACT III', 'ACT 3').replace('ACT II', 'ACT 2').replace('ACT I', 'ACT 1')\n",
    "mytext = mytext.replace('SCENE III', 'SCENE 3').replace('SCENE II', 'SCENE 2').replace('SCENE I', 'SCENE 1')\n",
    "\n",
    "mytext = mytext.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the text (+ punctuation): 3085\n"
     ]
    }
   ],
   "source": [
    "mytext_list = re.findall(r\"[\\w]+|[^\\s\\w]\", mytext)\n",
    "\n",
    "# occurrences of unique words in the list\n",
    "values, counts = np.unique(mytext_list, return_counts=True)\n",
    "print('Number of unique words in the text (+ punctuation):', len(values))\n",
    "\n",
    "# probability distribution\n",
    "prob_text = counts/len(mytext_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length: L[E,X]=8.693\n",
      "Shannon entropy:  H[X]=8.658\n",
      "\n",
      "Is Kraft inequality satisfied? True\n"
     ]
    }
   ],
   "source": [
    "# Huffman Algorithm\n",
    "encoding_text = Huffman_Algorithm(prob_text)\n",
    "\n",
    "print('Average length: L[E,X]=%.3f' %(avg_length(prob_text, encoding_text)))\n",
    "print('Shannon entropy:  H[X]=%.3f' %(entropy(prob_text)))\n",
    "\n",
    "print('\\nIs Kraft inequality satisfied?', kraft_inequality(encoding_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some examples of wordcodes:\n",
      "'!' -> 1110100\n",
      "'flatterer' -> 111110010011000\n",
      "'popular' -> 00000100000010\n",
      "'willing' -> 111100110100111\n"
     ]
    }
   ],
   "source": [
    "ex_ = [0, 1000, 2000, 3000]\n",
    "print('Some examples of wordcodes:')\n",
    "\n",
    "for ex in ex_:\n",
    "    print(\"'%s' -> %s\" %(values[ex], encoding_text[ex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding of the most probable word:\n",
      "',' -> 1100\n",
      "\n",
      "Encoding of the less probable word:\n",
      "'4' -> 111100111101110\n"
     ]
    }
   ],
   "source": [
    "i = np.argmax(prob_text)\n",
    "j = np.argmin(prob_text)\n",
    "\n",
    "print('Encoding of the most probable word:')\n",
    "print(\"'%s' -> %s\" %(values[i], encoding_text[i]))\n",
    "\n",
    "print('\\nEncoding of the less probable word:')\n",
    "print(\"'%s' -> %s\" %(values[j], encoding_text[j]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dabd4eacb9e3ddd54eefcebcf933935be170cfdef29c95630fe9376e024beb9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
